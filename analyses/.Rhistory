expchillcalc <- chilling(hrly, hrly$JDay[1], hrly$JDay[nrow(hrly)])
} else if (chilldat$chillbyhand[i]==1) {
yr <- as.numeric(chilldat$year[i])
if(chilldat$datasetID[i]=="jones12"){#jones12 Cuttings were exposed to either a 6-week or a 12-week chillingperiod, with each period split into three equal parts at one of the treatment temperatures (-4, 0, 4 or 8C).
temptreats<-strsplit(chilldat$chilltemp[i],",")
temp1<-as.numeric(temptreats[[1]][1])
temp2<-as.numeric(temptreats[[1]][2])
temp3<-as.numeric(temptreats[[1]][3])
hrly =
data.frame(
Temp = c(rep(temp1, times = 24 * as.numeric(chilldat$chilldays[i])/3),rep(temp2, times = 24 * as.numeric(chilldat$chilldays[i])/3),rep(temp3, times = 24 * as.numeric(chilldat$chilldays[i])/3)),
Year = rep(yr, times = 24 * round(as.numeric(chilldat$chilldays[i],digits=0))),
JDay = sort(rep(as.numeric(seq(1:round(as.numeric(chilldat$chilldays[i], digits=0)))), times = 24))
)
expchillcalc <- chilling(hrly, hrly$JDay[1], hrly$JDay[nrow(hrly)])
}
if(chilldat$datasetID[i]=="lamb37"){#lamb37 - 26.6F for 8 hr and 37.4 for 16 hr
temptreats<-strsplit(chilldat$chilltemp[i],",")
temp1<-as.numeric(temptreats[[1]][1])
temp2<-as.numeric(temptreats[[1]][2])
hrly =
data.frame(
Temp = rep(c(rep(temp1, times = 8),rep(temp2, times = 16)),times=as.numeric(chilldat$chilldays[i])),
Year = rep(yr, times = 24 * round(as.numeric(chilldat$chilldays[i],digits=0))),
JDay = sort(rep(as.numeric(seq(1:round(as.numeric(chilldat$chilldays[i], digits=0)))), times = 24))
)
expchillcalc <- chilling(hrly, hrly$JDay[1], hrly$JDay[nrow(hrly)])
}
if(chilldat$datasetID[i]=="li05"){##li05 - seedlings were chilled for 3 weeks at 6, and 3 weeks at 0.5
temptreats<-strsplit(chilldat$chilltemp[i],",")
temp1<-as.numeric(temptreats[[1]][1])
temp2<-as.numeric(temptreats[[1]][2])
hrly =
data.frame(
Temp = c(rep(temp1, times = 24 * as.numeric(chilldat$chilldays[i])/2),rep(temp2, times = 24 * as.numeric(chilldat$chilldays[i])/2)),
Year = rep(yr, times = 24 * round(as.numeric(chilldat$chilldays[i],digits=0))),
JDay = sort(rep(as.numeric(seq(1:round(as.numeric(chilldat$chilldays[i], digits=0)))), times = 24))
)
expchillcalc <- chilling(hrly, hrly$JDay[1], hrly$JDay[nrow(hrly)])
}
if(chilldat$datasetID[i]=="man10"){#man10- seedlings were chilled for one month at -3, and one month at 2
temptreats<-strsplit(chilldat$chilltemp[i],",")
temp1<-as.numeric(temptreats[[1]][1])
temp2<-as.numeric(temptreats[[1]][2])
hrly =
data.frame(
Temp = c(rep(temp1, times = 24 * as.numeric(chilldat$chilldays[i])/2),rep(temp2, times = 24 * as.numeric(chilldat$chilldays[i])/2)),
Year = rep(yr, times = 24 * round(as.numeric(chilldat$chilldays[i],digits=0))),
JDay = sort(rep(as.numeric(seq(1:round(as.numeric(chilldat$chilldays[i], digits=0)))), times = 24))
)
expchillcalc <- chilling(hrly, hrly$JDay[1], hrly$JDay[nrow(hrly)])
}
} else if(!is.na(chilldat$chilltemp[i]) & chilldat$chilldays[i] ==0 & !is.na(chilldat$chilldays[i]) & chilldat$chillbyhand[i]==0) {
expchillcalc <- data.frame("Chilling_Hours"=0, "Utah_Model"=0, "Chill_portions"=0)
} else {expchillcalc <- data.frame("Chilling_Hours"=NA, "Utah_Model"=NA, "Chill_portions"=NA) }
expchillcalcs <- rbind(expchillcalcs,
data.frame(datasetID = chilldat$datasetID[i],
ID_chilltreat = chilldat$ID_chilltreat[i],
expchillcalc[c("Chilling_Hours","Utah_Model","Chill_portions")]))
}
colnames(expchillcalcs)[3:5] <- c("Exp_Chilling_Hours","Exp_Utah_Model","Exp_Chill_portions")
#Merge field and experimental chilling data with the rest of the data
#Add experimental chilling. Right number of rows = 12862 rows, 63 columns
dat3 <- merge(d, expchillcalcs,
by.x = c("datasetID","ID_chilltreat"),
by.y=c("datasetID","ID_chilltreat"),
all.x=T)
dat3$ID_fieldsample.date2<-paste(dat3$datasetID,dat3$chill.lat,dat3$chill.long,dat3$fieldsample.date2,d2$addexpwarm, sep="_")
#Add field chilling calculations
###if you don't have climate data, read in chillcalc file,
chillcalcs <- read.csv("output/fieldchillcalcslatlong.csv", header=T)
chillcalcs <- chillcalcs[apply(chillcalcs, 1, function(x) all(!is.na(x))),] # only keep rows of all not NA.dim: 235   6
colnames(chillcalcs) <- c("ID_fieldsample.date2","Season","End_year","Field_Chilling_Hours","Field_Utah_Model","Field_Chill_portions")
#Check the sites that are missing chilling calculations because they are not North America or Europe (eg biasi12, cook00, gansert02, nishimoto95) or because they are too recent (Zohner16).
#Also, any site without field sample dates do not have field chilling, because do not have a field sample date.
#nochillcalcs <- unique(dat3$ID_fieldsample.date2[!dat3$ID_fieldsample.date2 %in% chillcalcs$ID_fieldsample.date2])
chillcalcs <- chillcalcs[chillcalcs$ID_fieldsample.date2 %in% dat3$ID_fieldsample.date2,]
#found 2 duplicate chilling calculation for laube14a: laube14a_48.403008_11.711811_2012-01-30_0 and laube14a_48.403008_11.711811_2012-03-14_0. For some reason, there are 2 years listed for this one- 2010/2011 and 2011/2012. since field sample date was january 2012, it should just be te 2011-2012 season. Remove
#no longer a problem so commenting the below out
#chillcalcs<-chillcalcs[-which(chillcalcs$ID_fieldsample.date2=="laube14a_48.403008_11.711811_2012-01-30_0" & chillcalcs$End_year==2011),]
#chillcalcs<-chillcalcs[-which(chillcalcs$ID_fieldsample.date2=="laube14a_48.403008_11.711811_2012-03-14_0" & chillcalcs$End_year==2011),]
dat4<-join(dat3, chillcalcs,by="ID_fieldsample.date2",match="all")
#We realized that some sites have included chilling estimates (rather than chiltemp and chillhours). Here we add those studies in:
#unique(dat4$cu.model)
#Four studies have field chilling reported with the utah model: "biasi12"    "cook00b"    "heide93"    "skuterud94"
dat4$Field_Utah_Model[dat4$cu.model=="Utah"|dat4$cu.model=="Utah model"]<-dat4$field.chill.units[dat4$cu.model=="Utah"|dat4$cu.model=="Utah model"]#149 rows
# chilling is calculated by multiplying chilldays and chilltemp together.
#however, if chilldays=0, sometimes chilltemp is listed as NA, yielding experimental chilling of NA when it should be 0.
dat4$chilldays[which(dat4$datasetID=="falusi90" & dat4$chilldays=="")] <-0 #no chilling for these
dat4$chilldays[which(dat4$datasetID=="falusi96" & dat4$study=="exp2"& dat4$fieldchill=="no")] <-0  ## No chilling. would fix 44 rows
dat4$chilldays[which(d$datasetID=="falusi96" & dat4$study=="exp3"& dat4$fieldchill=="no")] <-0    ##would fix 52 rows
###li05 short day controls got no chilling
dat4$chilldays[which(dat4$datasetID=="li05" & dat4$other.treatment=="short day controls")] <- 0
dat4$Exp_Chilling_Hours[which(dat4$chilldays=="0")]<-0
dat4$Exp_Utah_Model[which(dat4$chilldays=="0")]<-0
dat4$Exp_Chill_portions[which(dat4$chilldays=="0")]<-0
dat4$Exp_Chill_portions[which(dat4$datasetID=="caffarra11b")]
dat4$Field_Chill_portions[which(dat4$datasetID=="caffarra11b")]
dat4$Field_Chilling_Hours[which(dat4$datasetID=="caffarra11b")]
dat4$Field_Chilling_Hours[which(dat4$datasetID=="caffarra11b" & dat4$chilldays=="0")]
dat4$Field_Chill_portions[which(dat4$datasetID=="caffarra11b" & dat4$chilldays=="0")]
dat4$Exp_Utah_Model[which(dat4$datasetID=="caffarra11b" & dat4$chilldays=="0")]
dat4$Field_Utah_Model[which(dat4$datasetID=="caffarra11b" & dat4$chilldays=="0")]
source("chilling/totalchillcalc.R")
write.csv(dat4, "output/ospree_clean_withchill.csv", row.names=FALSE) ##
dat4$Total_Chilling_Hours[dat4$datasetID=="caffarra11b"]
dat4$Total_Utah_Model[dat4$datasetID=="caffarra11b"]
## housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory:
if(length(grep("Lizzie", getwd())>0)) { setwd("~/Documents/git/projects/treegarden/budreview/ospree/analyses")
} else if
(length(grep("Ignacio", getwd()))>0) { setwd("~/GitHub/ospree/analyses")
} else if
(length(grep("ailene", getwd()))>0) {setwd("/Users/aileneettinger/git/ospree/analyses")
} else
setwd("~/Documents/git/ospree/analyses")
# Load libraries
library(dplyr)
library(tidyr)
library(geosphere)
library(lubridate)
# 1. Get the data (that has already been cleaned for respvar and chilling)
d <- read.csv("output/ospree_clean_withchill.csv") # 29 May 2018: 12693
# 2. Need to deal with thermal time to days
source("bb_analysis/cleaning/clean_thermaltimetodays.R") # 29 May 2018: 12693
# 3. Clean phenstage to get a little more data (a little, but still!).
source("bb_analysis/cleaning/clean_respvarmore.R") # 29 May 2018: 12152
# 4. Select out the highest percentage of budburst only, and remove studies that contain duplicate data in two forms
source("bb_analysis/cleaning/multiresp.R") # as of 16 July 2017, deletes ~2400 rows (same in May 2018) 9717 rows
# 5. Clean ambient forcing
# 5a. Clean up entries where we can estimate the forcing from the paper (e.g., ramped temps or they give monthly temps)
source("bb_analysis/cleaning/clean_ambientforcing.R")
# 5b. Check date of daily climate files used in step 5c-
#if they are too old for your taste,run pulldailyclim.R and bb_daily_dataprep.R scripts (these take a while)
source("bb_analysis/cleaning/clean_checkdateofclimatedata.R") # As of 29 May 2018: 9717 rows
#if they are too old for your taste, run pulldailyclim.R and bb_daily_dataprep.R scripts (these take a while)
source("bb_analysis/cleaning/clean_checkdateofclimatedata.R") # As of 29 apr 2018: 9717 rows
# 5c. Clean ambient forcing data using daily climate data
source("bb_analysis/cleaning/clean_ambientforcingfromdailyclimate.R") # still 9717 rows
# 6. Clean/convert percentBB to days, using a specified target bud-burst level (i.e. 90%)
# ... with an allowable buffer (i.e., 55%)
source("bb_analysis/cleaning/clean_bbperctodays.R") # As of 8 June 2018: 7372 rows
# 7. Clean duplicate responses across treatments/categories)
source("bb_analysis/cleaning/clean_moreduplicates.R") # As of 8 June 2018, deletes 2 rows (7370).
# 8. Clean photoperiod entries to try to get as much data as possible
source("bb_analysis/cleaning/clean_photoperiod.R")
# 9. Write out the final file!
write.csv(d, "output/ospree_clean_withchill_BB.csv", row.names=FALSE) ## As of 8 June 2018: 7370 rows  (as of 29 May 2018: 7430)
## Clean the BB data within OSPREE ##
## started Nacho ###
## Making a master cleaning file for Budbreak analyses ... ##
## And away we go! ##
## housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory:
if(length(grep("Lizzie", getwd())>0)) { setwd("~/Documents/git/projects/treegarden/budreview/ospree/analyses")
} else if
(length(grep("Ignacio", getwd()))>0) { setwd("~/GitHub/ospree/analyses")
} else if
(length(grep("ailene", getwd()))>0) {setwd("/Users/aileneettinger/git/ospree/analyses")
} else
setwd("~/Documents/git/ospree/analyses")
# Load libraries
library(dplyr)
library(tidyr)
library(geosphere)
library(lubridate)
# 1. Get the data (that has already been cleaned for respvar and chilling)
d <- read.csv("output/ospree_clean_withchill.csv") # 29 May 2018: 12693
# 2. Need to deal with thermal time to days
source("bb_analysis/cleaning/clean_thermaltimetodays.R") # 29 May 2018: 12693
# 3. Clean phenstage to get a little more data (a little, but still!).
source("bb_analysis/cleaning/clean_respvarmore.R") # 29 May 2018: 12152
# 4. Select out the highest percentage of budburst only, and remove studies that contain duplicate data in two forms
source("bb_analysis/cleaning/multiresp.R") # as of 16 July 2017, deletes ~2400 rows (same in May 2018) 9717 rows
# 5. Clean ambient forcing
# 5a. Clean up entries where we can estimate the forcing from the paper (e.g., ramped temps or they give monthly temps)
source("bb_analysis/cleaning/clean_ambientforcing.R")
# 5b. Check date of daily climate files used in step 5c-
#if they are too old for your taste,run pulldailyclim.R and bb_daily_dataprep.R scripts (these take a while)
source("bb_analysis/cleaning/clean_checkdateofclimatedata.R") # As of 29 May 2018: 9717 rows
#if they are too old for your taste, run pulldailyclim.R and bb_daily_dataprep.R scripts (these take a while)
source("bb_analysis/cleaning/clean_checkdateofclimatedata.R") # As of 29 apr 2018: 9717 rows
# 5c. Clean ambient forcing data using daily climate data
source("bb_analysis/cleaning/clean_ambientforcingfromdailyclimate.R") # still 9717 rows
# 5b. Check date of daily climate files used in step 5c-
#if they are too old for your taste,run pulldailyclim.R and bb_daily_dataprep.R scripts (these take a while)
source("bb_analysis/cleaning/clean_checkdateofclimatedata.R") # As of 29 May 2018: 9717 rows
#if they are too old for your taste, run pulldailyclim.R and bb_daily_dataprep.R scripts (these take a while)
source("bb_analysis/cleaning/clean_checkdateofclimatedata.R") # As of 29 apr 2018: 9717 rows
dim(d)
unique(d$response.time)
hist(as.numeric(d$response.time))
unique(d$response)
hist(as.numeric(d$response))
dim(d)
targetvalue <- 90 # we want value closest to this
acceptablerange <- 0.55 # meaning as low as 49.5% allowed (e.g., 90-90*0.55=49.5) ## decreasing the acceptable range increases the amount of rows deleted (more values cease to be close enough to targetted values)
is.data.frame(d)
if(is.data.frame(d)){
subsetting.daysBB<-function(d,target.percent,type=c("add.columns","only.percentBB","BB_analysis")){
## generate new columns in dataset to store days to budburst results
d$response.time = as.numeric(as.character(d$response.time))
d$dbb=rep(NA,nrow(d))
d$maxperc_bb=rep(NA,nrow(d))
d$minperc_bb=rep(NA,nrow(d))
d$dist.50bb=rep(NA,nrow(d))
#dat_final <- data.frame(matrix(data=NA,nrow=0,ncol=7))
#colnames(dat_final) <- c("datasetID","study","treatment","dbb","maxperc_bb","minperc_bb","dist.50bb")
##Sites that use percent budburst
percbbsites<-subset(d,respvar=="percentbudburst")
#dim(percbbsites)
dataset <- unique(percbbsites$datasetID)
for(i in 1:length(dataset)){ # i = 1
#print(i)
dat1 <- percbbsites[which(percbbsites$datasetID==dataset[i]),]
#dim(dat1)
study<-unique(dat1$study)
##make new column that combines all treatments (columns 1:33) into one columns
dat1$treatment <- paste(dat1$genus,dat1$species, dat1$varetc,dat1$population,dat1$other.treatment,
dat1$dormancy_induction_temp,dat1$dormancy_induction_days,
dat1$dormancy_induction_photoperiod_day,dat1$dormancy_induction_photoperiod_night,
dat1$freeze.treatment.time,dat1$freeze.treatment.photoperiod_day,
dat1$freeze.treatment.photoperiod_night,dat1$freeze.treatment.temp_day,
dat1$freeze.treatment.temp_night,dat1$fieldchill,dat1$chilltemp,dat1$chillphotoperiod,
dat1$chilldays,dat1$number.longdays,dat1$photoperiod_day,
dat1$photoperiod_night, dat1$forcetemp, dat1$forcetemp_night,
dat1$irradiance,dat1$humidity, dat1$fieldsample.date,sep = ".")
for(j in 1:length(study)){ # j = 1
dat2<-dat1[which(dat1$study==study[j]),]
treat=unique(dat2$treatment)
dat2$response <- as.numeric(as.character(dat2$response))
#dim(d)
for(k in 1:length(treat)) { # k = 9 # This for loop cleans each treatment within studies with more than one treatment
#print(paste(i,j,k))
dat3 <- dat2[which(dat2$treatment==treat[k]),]
#print(paste(k,dim(dat3)[1]))
maxperc_bb<-max(as.numeric(dat3$response)) # maxpercent budburst
minperc_bb<-min(as.numeric(dat3$response)) # minpercent budburst - hopefully zero
#dists.to.target<-dist(dat3$response,upper=F)
dists.to.target<-dat3$response-target.percent
mindist<-which.min(abs(dists.to.target))
values.in.target<-which(dat3$response>(target.percent-target.percent*acceptablerange)&
dat3$response<(target.percent+target.percent*acceptablerange)&
dat3$response<100)
# Check if this can be estimated at all.
if(length(dat3$response[!is.na(dat3$response)])>1 & is.numeric(dat3$response.time)) {
# Check how many values are within 40% of target percent, if only one we proceed
if(length(values.in.target)==1){
#print("case1!!!")
index<-rownames(dat3[values.in.target,])
out.index<-rownames(dat3[which(!1:length(dat3$response)%in%values.in.target),])
d[index,"dbb"]<-dat3[values.in.target,"response.time"]
d[index,"maxperc_bb"]<-dat3[values.in.target,"response"]
d[index,"minperc_bb"]<-dat3[values.in.target,"response"]
d[index,"dist.50bb"]<-dat3[values.in.target,"response"]-target.percent
# remove whatever not within range
d<-d[!rownames(d)%in%out.index,]
}
# If there are more than 1 rows with values within the acceptable range (e.g. 25 or 40%) of target percent and values in the
# response variable are not equal to the targetted % we proceed
if(length(values.in.target)>1 & length(which(dat3$response==target.percent))==0){
#print("case2!!!")
index<-rownames(dat3[values.in.target[mindist],])
out.index<-rownames(dat3[which(!1:length(dat3$response)%in%mindist),])
d[index,"dbb"]<-dat3[values.in.target[mindist],"response.time"]
d[index,"maxperc_bb"]<-rep(max(dat3[values.in.target[mindist],"response"]),length(values.in.target[mindist]))
d[index,"minperc_bb"]<-rep(min(dat3[values.in.target[mindist],"response"]),length(values.in.target[mindist]))
d[index,"dist.50bb"]<-abs(dat3[values.in.target[mindist],"response"]-target.percent)
# remove whatever not within range
d<-d[!rownames(d)%in%out.index,]
#dim(d)
}
# If there are more than 1 rows with values within within the acceptable range of target percent and at least one value in the
# response variable is equal to the targetted % in the function we proceed
if(length(values.in.target)>1 & length(which(dat3$response==target.percent))>0){
#print("case3!!!")
index<-rownames(dat3[which(dat3$response==target.percent),])
out.index<-rownames(dat3[which(!1:length(dat3$response)%in%mindist),])
d[index,"dbb"]<-dat3[which(dat3$response==target.percent),"response.time"]
d[index,"maxperc_bb"]<-dat3[which(dat3$response==target.percent),"response"]
d[index,"minperc_bb"]<-dat3[which(dat3$response==target.percent),"response"]
d[index,"dist.50bb"]<-rep(0,length(index))
# remove whatever not within range
d<-d[!rownames(d)%in%out.index,]
}
# If there are more than 1 rows but no values fall within within the acceptable range of target percent and at least one value in the
# response variable is equal to the targetted % in the function we proceed
if(length(values.in.target)==0 & length(dat3$response)>0){
#print("case4!!!")
#index<-rownames(dat3[mindist,])
#out.index<-rownames(dat3[which(!1:length(dat3$response)%in%mindist),])
out.index<-rownames(dat3)
#d[index,"dbb"]<-dat3[index,"response.time"]
#d[index,"maxperc_bb"]<-dat3[index,"response"]
#d[index,"minperc_bb"]<-dat3[index,"response"]
#d[index,"dist.50bb"]<-rep(dists.to.target[mindist],length(index))
# remove whatever not within range
d<-d[!rownames(d)%in%out.index,]
}
}
# If there is only 1 row with values we keep it only if it is within the range
if(length(dat3$response[!is.na(dat3$response)])==1 & is.numeric(dat3$response.time)){
if(length(values.in.target)==0){
out.index<-rownames(dat3)
# remove whatever not within range
d<-d[!rownames(d)%in%out.index,]
}
if(length(values.in.target)>0){
index<-rownames(dat3[values.in.target,])
out.index<-rownames(dat3[which(!1:length(dat3$response)%in%values.in.target),])
d[index,"dbb"]<-dat3[values.in.target,"response.time"]
d[index,"maxperc_bb"]<-dat3[values.in.target,"response"]
d[index,"minperc_bb"]<-dat3[values.in.target,"response"]
d[index,"dist.50bb"]<-dat3[values.in.target,"response"]-target.percent
# remove whatever not within range
d<-d[!rownames(d)%in%out.index,]
}
}
}
}
}
if(type=="BB_analysis"){
d.subset.1<-subset(d,respvar.simple=="percentbudburst" & !is.na(response.time))
#d.subset.2<-subset(d,!is.na(dbb))
d.subset.2<-subset(d,respvar.simple!="percentbudburst")
d.subsetted<-rbind(d.subset.1,d.subset.2)
d.subsetted$response.time[which(!is.na(d.subsetted$dbb))]<-d.subsetted$dbb[which(!is.na(d.subsetted$dbb))]
}
if(type=="leave.nearest.2.target"){
d.subset.1<-subset(d,respvar.simple=="percentbudburst" & !is.na(response.time))
#d.subset.2<-subset(d,!is.na(dbb))
d.subset.2<-subset(d,respvar.simple!="percentbudburst")
d.subsetted<-rbind(d.subset.1,d.subset.2)
d.subsetted$response.time[which(!is.na(d.subsetted$dbb))]<-d.subsetted$dbb[which(!is.na(d.subsetted$dbb))]
}
if(type=="add.columns"){
d.subsetted <- d
}
if(type=="only.percentBB"){
d.subsetted<-subset(d,!is.na(dbb))
}
return(d.subsetted)
}
d.subset <- subsetting.daysBB(d, targetvalue, "BB_analysis")
d <- d.subset
} else {
print("Error: d not a data.frame")
}
dim(d)
## Almost done! Now remove the values too low
d.subset.1 <- subset(d, respvar.simple=="percentbudburst" & !is.na(response.time))
d.subset.2 <- subset(d, respvar.simple!="percentbudburst")
d.subset.1.rmlowvalues <- subset(d.subset.1, is.na(dbb)==FALSE)
d.subsetted <- rbind(d.subset.1.rmlowvalues, d.subset.2)
d.subsetted <- d
dim(d)
dim(d.subsetted)
dim(d.subset.1)
dim(d.subset.2)
d.subset.1.rmlowvalues <- subset(d.subset.1, is.na(dbb)==FALSE)
dim(d.subset.1.rmlowvalues)
head(d.subset.1.rmlowvalues)
unique(d$respvar.simple)
unique(d.subsetted$respvar.simple)
subsetting.daysBB<-function(d,target.percent,type=c("add.columns","only.percentBB","BB_analysis")){
## generate new columns in dataset to store days to budburst results
d$response.time = as.numeric(as.character(d$response.time))
d$dbb=rep(NA,nrow(d))
d$maxperc_bb=rep(NA,nrow(d))
d$minperc_bb=rep(NA,nrow(d))
d$dist.50bb=rep(NA,nrow(d))
#dat_final <- data.frame(matrix(data=NA,nrow=0,ncol=7))
#colnames(dat_final) <- c("datasetID","study","treatment","dbb","maxperc_bb","minperc_bb","dist.50bb")
##Sites that use percent budburst
percbbsites<-subset(d,respvar=="percentbudburst")
#dim(percbbsites)
dataset <- unique(percbbsites$datasetID)
for(i in 1:length(dataset)){ # i = 1
#print(i)
dat1 <- percbbsites[which(percbbsites$datasetID==dataset[i]),]
#dim(dat1)
study<-unique(dat1$study)
##make new column that combines all treatments (columns 1:33) into one columns
dat1$treatment <- paste(dat1$genus,dat1$species, dat1$varetc,dat1$population,dat1$other.treatment,
dat1$dormancy_induction_temp,dat1$dormancy_induction_days,
dat1$dormancy_induction_photoperiod_day,dat1$dormancy_induction_photoperiod_night,
dat1$freeze.treatment.time,dat1$freeze.treatment.photoperiod_day,
dat1$freeze.treatment.photoperiod_night,dat1$freeze.treatment.temp_day,
dat1$freeze.treatment.temp_night,dat1$fieldchill,dat1$chilltemp,dat1$chillphotoperiod,
dat1$chilldays,dat1$number.longdays,dat1$photoperiod_day,
dat1$photoperiod_night, dat1$forcetemp, dat1$forcetemp_night,
dat1$irradiance,dat1$humidity, dat1$fieldsample.date,sep = ".")
for(j in 1:length(study)){ # j = 1
dat2<-dat1[which(dat1$study==study[j]),]
treat=unique(dat2$treatment)
dat2$response <- as.numeric(as.character(dat2$response))
#dim(d)
for(k in 1:length(treat)) { # k = 9 # This for loop cleans each treatment within studies with more than one treatment
#print(paste(i,j,k))
dat3 <- dat2[which(dat2$treatment==treat[k]),]
#print(paste(k,dim(dat3)[1]))
maxperc_bb<-max(as.numeric(dat3$response)) # maxpercent budburst
minperc_bb<-min(as.numeric(dat3$response)) # minpercent budburst - hopefully zero
#dists.to.target<-dist(dat3$response,upper=F)
dists.to.target<-dat3$response-target.percent
mindist<-which.min(abs(dists.to.target))
values.in.target<-which(dat3$response>(target.percent-target.percent*acceptablerange)&
dat3$response<(target.percent+target.percent*acceptablerange)&
dat3$response<100)
# Check if this can be estimated at all.
if(length(dat3$response[!is.na(dat3$response)])>1 & is.numeric(dat3$response.time)) {
# Check how many values are within 40% of target percent, if only one we proceed
if(length(values.in.target)==1){
#print("case1!!!")
index<-rownames(dat3[values.in.target,])
out.index<-rownames(dat3[which(!1:length(dat3$response)%in%values.in.target),])
d[index,"dbb"]<-dat3[values.in.target,"response.time"]
d[index,"maxperc_bb"]<-dat3[values.in.target,"response"]
d[index,"minperc_bb"]<-dat3[values.in.target,"response"]
d[index,"dist.50bb"]<-dat3[values.in.target,"response"]-target.percent
# remove whatever not within range
d<-d[!rownames(d)%in%out.index,]
}
# If there are more than 1 rows with values within the acceptable range (e.g. 25 or 40%) of target percent and values in the
# response variable are not equal to the targetted % we proceed
if(length(values.in.target)>1 & length(which(dat3$response==target.percent))==0){
#print("case2!!!")
index<-rownames(dat3[values.in.target[mindist],])
out.index<-rownames(dat3[which(!1:length(dat3$response)%in%mindist),])
d[index,"dbb"]<-dat3[values.in.target[mindist],"response.time"]
d[index,"maxperc_bb"]<-rep(max(dat3[values.in.target[mindist],"response"]),length(values.in.target[mindist]))
d[index,"minperc_bb"]<-rep(min(dat3[values.in.target[mindist],"response"]),length(values.in.target[mindist]))
d[index,"dist.50bb"]<-abs(dat3[values.in.target[mindist],"response"]-target.percent)
# remove whatever not within range
d<-d[!rownames(d)%in%out.index,]
#dim(d)
}
# If there are more than 1 rows with values within within the acceptable range of target percent and at least one value in the
# response variable is equal to the targetted % in the function we proceed
if(length(values.in.target)>1 & length(which(dat3$response==target.percent))>0){
#print("case3!!!")
index<-rownames(dat3[which(dat3$response==target.percent),])
out.index<-rownames(dat3[which(!1:length(dat3$response)%in%mindist),])
d[index,"dbb"]<-dat3[which(dat3$response==target.percent),"response.time"]
d[index,"maxperc_bb"]<-dat3[which(dat3$response==target.percent),"response"]
d[index,"minperc_bb"]<-dat3[which(dat3$response==target.percent),"response"]
d[index,"dist.50bb"]<-rep(0,length(index))
# remove whatever not within range
d<-d[!rownames(d)%in%out.index,]
}
# If there are more than 1 rows but no values fall within within the acceptable range of target percent and at least one value in the
# response variable is equal to the targetted % in the function we proceed
if(length(values.in.target)==0 & length(dat3$response)>0){
#print("case4!!!")
#index<-rownames(dat3[mindist,])
#out.index<-rownames(dat3[which(!1:length(dat3$response)%in%mindist),])
out.index<-rownames(dat3)
#d[index,"dbb"]<-dat3[index,"response.time"]
#d[index,"maxperc_bb"]<-dat3[index,"response"]
#d[index,"minperc_bb"]<-dat3[index,"response"]
#d[index,"dist.50bb"]<-rep(dists.to.target[mindist],length(index))
# remove whatever not within range
d<-d[!rownames(d)%in%out.index,]
}
}
# If there is only 1 row with values we keep it only if it is within the range
if(length(dat3$response[!is.na(dat3$response)])==1 & is.numeric(dat3$response.time)){
if(length(values.in.target)==0){
out.index<-rownames(dat3)
# remove whatever not within range
d<-d[!rownames(d)%in%out.index,]
}
if(length(values.in.target)>0){
index<-rownames(dat3[values.in.target,])
out.index<-rownames(dat3[which(!1:length(dat3$response)%in%values.in.target),])
d[index,"dbb"]<-dat3[values.in.target,"response.time"]
d[index,"maxperc_bb"]<-dat3[values.in.target,"response"]
d[index,"minperc_bb"]<-dat3[values.in.target,"response"]
d[index,"dist.50bb"]<-dat3[values.in.target,"response"]-target.percent
# remove whatever not within range
d<-d[!rownames(d)%in%out.index,]
}
}
}
}
}
if(type=="BB_analysis"){
d.subset.1<-subset(d,respvar.simple=="percentbudburst" & !is.na(response.time))
#d.subset.2<-subset(d,!is.na(dbb))
d.subset.2<-subset(d,respvar.simple!="percentbudburst")
d.subsetted<-rbind(d.subset.1,d.subset.2)
d.subsetted$response.time[which(!is.na(d.subsetted$dbb))]<-d.subsetted$dbb[which(!is.na(d.subsetted$dbb))]
}
if(type=="leave.nearest.2.target"){
d.subset.1<-subset(d,respvar.simple=="percentbudburst" & !is.na(response.time))
#d.subset.2<-subset(d,!is.na(dbb))
d.subset.2<-subset(d,respvar.simple!="percentbudburst")
d.subsetted<-rbind(d.subset.1,d.subset.2)
d.subsetted$response.time[which(!is.na(d.subsetted$dbb))]<-d.subsetted$dbb[which(!is.na(d.subsetted$dbb))]
}
if(type=="add.columns"){
d.subsetted <- d
}
if(type=="only.percentBB"){
d.subsetted<-subset(d,!is.na(dbb))
}
return(d.subsetted)
}
