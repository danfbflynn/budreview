<<<<<<< Updated upstream
grid.arrange(ilemuc, betall, ncol=1, nrow=2)
ilemuc<-ggplot(ile, aes(x=doy, y=risk)) + geom_line() + coord_cartesian(ylim=0:20) +
annotate("rect", xmin=82, xmax=97, ymin=1, ymax=6, alpha=0.1, color="red") +
xlab("Day of Year") + ylab("Frost Damage Risk") +
annotate("text", x = 140:150, y = 18, label = "ILEMUC")
betall<-ggplot(bet, aes(x=doy, y=risk)) + geom_line() + coord_cartesian(ylim=0:20) +
annotate("rect", xmin=82, xmax=97, ymin=1, ymax=6, alpha=0.1, color="red") +
xlab("Day of Year") + ylab("Frost Damage Risk") +
annotate("text", x = 140:150, y = 18, label = "BETALL")
grid.arrange(ilemuc, betall, ncol=1, nrow=2)
ilemuc<-ggplot(ile, aes(x=doy, y=risk)) + geom_line() + coord_cartesian(ylim=0:20) +
annotate("rect", xmin=82, xmax=97, ymin=1, ymax=6, alpha=0.1, color="red") +
xlab("Day of Year") + ylab("Frost Damage Risk") +
annotate("text", x = 140, y = 18, label = "ILEMUC")
betall<-ggplot(bet, aes(x=doy, y=risk)) + geom_line() + coord_cartesian(ylim=0:20) +
annotate("rect", xmin=82, xmax=97, ymin=1, ymax=6, alpha=0.1, color="red") +
xlab("Day of Year") + ylab("Frost Damage Risk") +
annotate("text", x = 140, y = 18, label = "BETALL")
grid.arrange(ilemuc, betall, ncol=1, nrow=2)
ilemuc<-ggplot(ile, aes(x=doy, y=risk)) + geom_line() + coord_cartesian(ylim=0:20) +
annotate("rect", xmin=82, xmax=97, ymin=1, ymax=6, alpha=0.1, color="red") +
xlab("Day of Year") + ylab("Frost Damage Risk") +
annotate("text", x = 140, y = 18, label = "Ilex mucronata")
betall<-ggplot(bet, aes(x=doy, y=risk)) + geom_line() + coord_cartesian(ylim=0:20) +
annotate("rect", xmin=82, xmax=97, ymin=1, ymax=6, alpha=0.1, color="red") +
xlab("Day of Year") + ylab("Frost Damage Risk") +
annotate("text", x = 140, y = 18, label = "Betula alleghaniensis")
grid.arrange(ilemuc, betall, ncol=1, nrow=2)
ilemuc<-ggplot(ile, aes(x=doy, y=risk)) + geom_line() + coord_cartesian(ylim=0:20) +
annotate("rect", xmin=82, xmax=97, ymin=1, ymax=6, alpha=0.1, color="red") +
xlab("Day of Year") + ylab("Frost Damage Risk") +
annotate("text", x = 140, y = 18, label = "Ilex mucronata")
betall<-ggplot(bet, aes(x=doy, y=risk)) + geom_line() + coord_cartesian(ylim=0:20) +
annotate("rect", xmin=82, xmax=97, ymin=1, ymax=6, alpha=0.1, color="red") +
xlab("Day of Year") + ylab("Frost Damage Risk") +
annotate("text", x = 135, y = 18, label = "Betula alleghaniensis")
grid.arrange(ilemuc, betall, ncol=1, nrow=2)
ilemuc<-ggplot(ile, aes(x=doy, y=risk)) + geom_line() + coord_cartesian(ylim=0:20) +
annotate("rect", xmin=82, xmax=97, ymin=1, ymax=6, alpha=0.1, color="red") +
xlab("Day of Year") + ylab("Frost Damage Risk") +
annotate("text", x = 140, y = 18, label = "Ilex mucronata")
betall<-ggplot(bet, aes(x=doy, y=risk)) + geom_line() + coord_cartesian(ylim=0:20) +
annotate("rect", xmin=82, xmax=97, ymin=1, ymax=6, alpha=0.1, color="red") +
xlab("Day of Year") + ylab("Frost Damage Risk") +
annotate("text", x = 137, y = 18, label = "Betula alleghaniensis")
grid.arrange(ilemuc, betall, ncol=1, nrow=2)
ilemuc<-ggplot(ile, aes(x=doy, y=risk)) + geom_line() + coord_cartesian(ylim=0:20) +
annotate("rect", xmin=82, xmax=97, ymin=1, ymax=6, alpha=0.1, color="red") +
xlab("Day of Year") + ylab("Frost Damage Risk") +
annotate("text", x = 140, y = 18, label = "Ilex mucronata")
betall<-ggplot(bet, aes(x=doy, y=risk)) + geom_line() + coord_cartesian(ylim=0:20) +
annotate("rect", xmin=82, xmax=97, ymin=1, ymax=6, alpha=0.1, color="red") +
xlab("Day of Year") + ylab("Frost Damage Risk") +
annotate("text", x = 140, y = 18, label = "Betula alleghaniensis")
grid.arrange(ilemuc, betall, ncol=1, nrow=2)
rm(list=ls()) # remove everything currently held in the R memory
options(stringsAsFactors=FALSE)
graphics.off()
# Load libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(ncdf4)
library(Interpol.T)
library(chillR)
library(raster)
library(maptools)
library(rgeos)
library(rgdal)
raster1<-brick("~/Desktop/tn_0.25deg_reg_v16.0.nc", varname="tn", sep="")
eur.temp<-nc_open("~/Desktop/tn_0.25deg_reg_v16.0.nc")
raster1<-brick("//WeldShare/Wolkovich Lab/Budburst Review - Ospree/Climate Data/tn_0.25deg_reg_v15.0.nc", varname="tn", sep="")
eur.temp <- nc_open("//128.103.155.31/WeldShare/Wolkovich Lab/Budburst Review - Ospree/Climate Data/tn_0.25deg_reg_v15.0.nc")
plot(raster1[[45]])
#raster1 <- setMinMax(raster1)
#length(doy)/365
doy<-ncvar_get(eur.temp, "time")
doy<-as.Date(doy, origin="1950-01-01")
day<-substr(doy, 9,10)
year<-as.numeric(substr(doy, 1, 4))
month<-as.numeric(substr(doy, 6, 7))
timevec<-paste(year, month, day, sep="-")
years.vec<-as.character(timevec, format="Y-%m-%d")
year<-as.numeric(substr(years.vec, 1, 4))
#doy.vec<-as.POSIXlt(names(raster1), format="X%j")
dates<-as.Date(years.vec)
names(raster1)<-dates
empty.raster<-raster1[[1]]
values(empty.raster)<-NA
years<-1950:2016
leaps <- function(x) {
m <- c()
for(i in 1:50) {
year.i <- years[which(((years %% 4 == 0) & (years %% 100 !=0) | (years %% 400 == 0)))]
m <- c(m, year.i)
}
return(m)
}
leap.years<-as.data.frame(leaps(1))
leap.years<-leap.years[!duplicated(leaps(1)),]
#year<-1950:2016
empty.raster<-raster1[[1]]
num.false.spring.year<-list()
#dates.false.spring<-list()
for(i in 1951:1983){#i=1952
print(i)
year.i<-i
is.leap<-ifelse(year.i%in%leap.years,TRUE,FALSE)
sequence.years<-which(year==year.i)
#length(sequence.years)
raster.sub<-subset(raster1,sequence.years)
#numnonas<-sum(!is.na(values(raster.sub[[1]])))
rast.array<-array(75,dim=c(ncell(raster.sub),181))
if(is.leap){
for(j in 75:181){ ## you need to change
print(paste(year.i,j))
rast.array[,j]<-values(raster.sub[[j]])
=======
getwd()
getwd()
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory:
if(length(grep("Lizzie", getwd())>0)) {setwd("~/Documents/git/projects/treegarden/budreview/ospree/analyses")
} else if
(length(grep("ailene", getwd()))>0) {setwd("/Users/aileneettinger/git/ospree/analyses")
}else
setwd("~/Documents/git/ospree/analyses")
# Load libraries
library(dplyr)
library(tidyr)
library(plyr)
library(ncdf4)
library(Interpol.T)
library(chillR)
# 1. Get the data
d <- read.csv("output/ospree_clean.csv")
# 2. Clean the chilltemp column
source("chilling/cleaning_chilltemp.R")
#3. Clean the provenance.latitude and provenance.longitude columns, to get appropriate locations
#source("chilling/cleaning_provlatlong.R")
#This step was moved to the cleaning folder
# 4. Estimate field chilling (using growing or provenance lat/long to pull climate data)- STEP 4B REQUIRES EXTERNAL HARD DRIVE
# 4a: summarize lat/longs needed to pull climate data from europe and north america
source("chilling/fieldchillcalc_latlong.R")
load("output/fieldclimate.RData")
dat<-read.csv("output/fieldchillcalcslatlong.csv")
head(dat)
dim(dat)
tail(dat)
unique(eur$datasetID)
unique(nam$datasetID)
head(nam)
tail(nam)
tail(dat)
cbind(dat$year,dat$End_year)
head(dat)
cbind(dat$datasetIDlatlong,dat$End_year)
nam[i,"fieldsample.date2"]!=""
nam[nam$fieldsample.date2"=="",]
head(nam)
nam[nam$fieldsample.date2=="",]
substr(endday,1,4)==yr & as.numeric(substr(endday,6,7)
i=1
# find this location
lo <- nam[i,"chill.long"]
la <- nam[i,"chill.lat"]
yr <- as.numeric(nam[i,"year"])
nam[i,]
substr(endday,1,4)==yr & as.numeric(substr(endday,6,7))<=9
nam[i,"fieldsample.date2"]!=""
# start and end days of the climate data we need to calculate chilling, for the focal lat/long. This is in days since baseline date (sept 1) Set to GMT to avoid daylight savings insanity
# using d$fieldsample.date2 (this is the same as fieldsampledate, but formatted as  "%Y-%m-%d")
endday <- strptime(nam[i,"fieldsample.date2"],"%Y-%m-%d", tz = "GMT")
endday
substr(endday,1,4)==yr & as.numeric(substr(endday,6,7)
)
substr(endday,1,4)==yr & as.numeric(substr(endday,6,7))>=9
substr(endday,1,4)==yr-1 & as.numeric(substr(endday,6,7))<=12  & as.numeric(substr(endday,6,7))>=9
stday <- strptime(paste(yr-1, "09-01", sep="-"),"%Y-%m-%d", tz="GMT")
stday
nam[i,]
prevmo <- paste(yr-1, formatC(9:substr(endday,6,7), width=2, flag="0"), sep="");# use previous year's fall months of chilling (Sept-whenever collection occured)}
prevmo
chillmo<-prevmo
chillmo
substr(endday,1,4)==yr-1 & as.numeric(substr(endday,6,7))<=12  & as.numeric(substr(endday,6,7))<9
substr(endday,1,4)==yr-1 & as.numeric(substr(endday,6,7))<=12  & as.numeric(substr(endday,6,7))<9){#when sampling occurred in previous year as study, NOT during the fa
substr(endday,1,4)==yr-1 & as.numeric(substr(endday,6,7))<=12  & as.numeric(substr(endday,6,7))<9
nam[i,]
nam[2,]
dat[dat$datasetIDlatlong==ashby62_41.788_-87.599_1957-01-08_0]
dat[dat$datasetIDlatlong=="ashby62_41.788_-87.599_1957-01-08_0",]
nafiles <- dir(climatedrive)[grep("livneh", dir(climatedrive))]
nafiles <- dir(climatedrive)[grep("livneh", dir(climatedrive))]
nafiles <- dir(climatedrive)[grep("livneh", dir(climatedrive))]
## housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory:
if(length(grep("Lizzie", getwd())>0)) {setwd("~/Documents/git/projects/treegarden/budreview/ospree/analyses")
} else if
(length(grep("ailene", getwd()))>0) {setwd("/Users/aileneettinger/git/ospree/analyses")
}else
setwd("~/Documents/git/ospree/analyses")
# Load libraries
library(dplyr)
library(tidyr)
library(plyr)
library(ncdf4)
library(Interpol.T)
library(chillR)
# 1. Get the data
d <- read.csv("output/ospree_clean.csv")
source("chilling/cleaning_chilltemp.R")
# 4a: summarize lat/longs needed to pull climate data from europe and north america
source("chilling/fieldchillcalc_latlong.R")
# 4b: Set the location of the external hard drive, then pull daily climate data for Europe and North America
#Skip ahead to 4e if you do not have the climate data drive
climatedrive = "/Volumes/Ospree Climate" # (Ospree Climate is name of the external drive, change with new device)
climatedrive = "/Volumes/climate" #Ailene's climate data drive
# 4c. pull climate data from europe
source("chilling/pullclimate_eur.R")
# 4d: pull climate data from north america
#tempval <- list() #required to just pull nam climate
source("chilling/pullclimate_nam.R")
warnings()
tempval[[as.character(nam[i,"ID_fieldsample.date2"])]]
# If you want to (as Lizzie does) you can write out tempval, which is all the climate pulled in a list form
save(tempval, file="output/fieldclimate.RData")
chillmo
# 4e: Interpolate hourly temperatures from the daily values
# & chilling using three different metrics
#(If you want to avoid connecting to the external hard drive, then start here)
#load this .RData workspace)
#load("output/fieldclimate.RData")
source("chilling/interpolclimate.R")
head(dat)
source("chilling/totalchillcalc.R")
head(dat4)
dat4$missingCH<-0
dat4$missingCH[which(is.na(dat4$Total_Chilling_Hours))]<-1
chilltab<-table(dat4$datasetID,dat4$missingCH)
missing<-chilltab[chilltab[,2]>0,]
missing
chilltab
nam$datasetID
i=41
# find this location
lo <- nam[i,"chill.long"]
la <- nam[i,"chill.lat"]
nam[i,]
nam[i,"fieldsample.date2"]!=""
endday <- strptime(nam[i,"fieldsample.date2"],"%Y-%m-%d", tz = "GMT"
)
endday
substr(endday,1,4)==yr & as.numeric(substr(endday,6,7))<=9
substr(endday,1,4)==yr & as.numeric(substr(endday,6,7))>=9
substr(endday,1,4)==yr-1 & as.numeric(substr(endday,6,7))<=12  & as.numeric(substr(endday,6,7))>=9
substr(endday,1,4)==yr-1 & as.numeric(substr(endday,6,7))<=12  & as.numeric(substr(endday,6,7))<9
#do everything in reference to field sample year becuase the year column is too variable
yr<-as.numeric(substr(nam[i,"fieldsample.date2"],1,4))
# make sure longitudes are negative, need to be for North America this step is now done in "cleaning/clean_latlong" so it is no longer necessary
#if(lo > 0) { lo = lo*-1 }
yr<-as.numeric(substr(nam[i,"fieldsample.date2"],1,4))
#do everything in reference to field sample year becuase the year column is too variable
stday <- strptime(paste(yr-1, "09-01", sep="-"),"%Y-%m-%d", tz="GMT")#start day for chilling is september 1
stday
nam[i,"fieldsample.date2"]!="" & as.numeric(substr(nam[i,"fieldsample.date2"],6,7))>=9
nam[i,"fieldsample.date2"]!="" & as.numeric(substr(nam[i,"fieldsample.date2"],6,7))<9
as.numeric(substr(endday,6,7))<=12
if(nam[i,"fieldsample.date2"]!="" & as.numeric(substr(nam[i,"fieldsample.date2"],6,7))<9){
stday <- strptime(paste(yr-1, "09-01", sep="-"),"%Y-%m-%d", tz="GMT")}#If field sample date is before september 1, then we use the chilling from the previous year.
# find this location
lo <- nam[i,"chill.long"]
la <- nam[i,"chill.lat"]
# make sure longitudes are negative, need to be for North America this step is now done in "cleaning/clean_latlong" so it is no longer necessary
#if(lo > 0) { lo = lo*-1 }
yr<-as.numeric(substr(nam[i,"fieldsample.date2"],1,4))
# start and end days of the climate data we need to calculate chilling, for the focal lat/long.
#This is in days since baseline date (sept 1) Set to GMT to avoid daylight savings insanity
# using d$fieldsample.date2 (this is the same as fieldsampledate, but formatted as  "%Y-%m-%d")
#do everything in reference to field sample year becuase the year column is too variable
if(nam[i,"fieldsample.date2"]!=""){endday <- strptime(nam[i,"fieldsample.date2"],"%Y-%m-%d", tz = "GMT")}
if(nam[i,"fieldsample.date2"]==""){endday <- strptime(paste(yr, "04-30", sep="-"),"%Y-%m-%d", tz = "GMT")}#I think we have field sample dates for everything, but just in case...
if(nam[i,"fieldsample.date2"]!="" & as.numeric(substr(nam[i,"fieldsample.date2"],6,7))>=9){
stday <- strptime(paste(yr, "09-01", sep="-"),"%Y-%m-%d", tz="GMT")
chillmo<-paste(yr, formatC(9:substr(endday,6,7), width=2, flag="0"), sep="")
}#If field sample date is after september 1, then we use the chilling from the current year, since sept 1
if(nam[i,"fieldsample.date2"]!="" & as.numeric(substr(nam[i,"fieldsample.date2"],6,7))<9){
stday <- strptime(paste(yr-1, "09-01", sep="-"),"%Y-%m-%d", tz="GMT")}#If field sample date is before september 1, then we use the chilling from the previous year.
prevmo <- paste(yr-1, formatC(9:12, width=2, flag="0"), sep="");# use previous year's fall months of chilling (Sept-Dec)
endmo<-substr(endday,6,7);#month of sampling date
thismo <- paste(yr, formatC(1:endmo, width=2, flag="0"), sep="")#months from current year of chilling, through sampling date (Jan-whenever sampled)
chillmo<-c(prevmo, thismo)
>>>>>>> Stashed changes
}
# now loop over these year-month combo files and get temperature values for this date range.
mins <- maxs <- vector()
for(j in c(chillmo)){ # j = "200009"
file <- file.path(climatedrive,nafiles[grep(j, nafiles)])
jx <- nc_open(file)
diff.long.cell <- abs(jx$dim$lon$vals-as.numeric(lo))#differences between all longitudes & latitudes in the focal month's dataset and longitude[i]
diff.lat.cell <- abs(jx$dim$lat$vals-as.numeric(la))
long.cell <- which(diff.long.cell==min(diff.long.cell))[1] #select the closest longitude & latitude with climate data to longitude[i]
lat.cell <- which(diff.lat.cell==min(diff.lat.cell))[1]
long.cell <- which.min(abs(jx$dim$lon$vals-as.numeric(lo)))
lat.cell <- which.min(abs(jx$dim$lat$vals-as.numeric(la)))
mintest<-ncvar_get(jx,'Tmin',start=c(long.cell,lat.cell,1),count=c(1,1,-1))#checl that the lat/long combinations has temperature data.
#if no temperature data for the focal lat/long, choose the next closest one.
#the below code cose up to 0.1 degrees (~10km) away from the closest lat/long)
if(is.na(unique(mintest))){#if there are no temp data for the selected lat/long, chosee a different one
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
long.cell <- which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1] #select the closest longitude & latitude with climate data to longitude[i]
lat.cell <- which(diff.lat.cell==min(diff.lat.cell,na.rm=TRUE))[1]
mintest<-ncvar_get(jx,'Tmin',start=c(long.cell,lat.cell,1),count=c(1,1,-1))
if(is.na(unique(mintest))){
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
long.cell <- which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1] #select the closest longitude & latitude with climate data to longitude[i]
lat.cell <- which(diff.lat.cell==min(diff.lat.cell,na.rm=TRUE))[1]
mintest<-ncvar_get(jx,'Tmin',start=c(long.cell,lat.cell,1),count=c(1,1,-1))
if(is.na(unique(mintest))){
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
long.cell <- which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1] #select the closest longitude & latitude with climate data to longitude[i]
lat.cell <- which(diff.lat.cell==min(diff.lat.cell,na.rm=TRUE))[1]
}}}
mins <- c(mins, ncvar_get(jx,'Tmin',start=c(long.cell,lat.cell,1),count=c(1,1,-1)))#minimum temperatures for selected lat/long
maxs <- c(maxs, ncvar_get(jx,'Tmax',start=c(long.cell,lat.cell,1),count=c(1,1,-1)))#minimum temperatures for selected lat/long
nc_close(jx)
}
tempval[[as.character(nam[i,"ID_fieldsample.date2"])]] <- data.frame(Lat = la,Long = lo,Date = as.character(seq(stday, endday, by = "day")),
Tmin = mins[1:length(seq(stday, endday, by = "day"))], Tmax =maxs[1:length(seq(stday, endday, by = "day"))])#
}
tempval[[as.character(nam[i,"ID_fieldsample.date2"])]]
nam[i,"ID_fieldsample.date2"])
nam[i,]
for(j in c(chillmo)){ # j = "200009"
file <- file.path(climatedrive,nafiles[grep(j, nafiles)])
jx <- nc_open(file)
diff.long.cell <- abs(jx$dim$lon$vals-as.numeric(lo))#differences between all longitudes & latitudes in the focal month's dataset and longitude[i]
diff.lat.cell <- abs(jx$dim$lat$vals-as.numeric(la))
long.cell <- which(diff.long.cell==min(diff.long.cell))[1] #select the closest longitude & latitude with climate data to longitude[i]
lat.cell <- which(diff.lat.cell==min(diff.lat.cell))[1]
long.cell <- which.min(abs(jx$dim$lon$vals-as.numeric(lo)))
lat.cell <- which.min(abs(jx$dim$lat$vals-as.numeric(la)))
mintest<-ncvar_get(jx,'Tmin',start=c(long.cell,lat.cell,1),count=c(1,1,-1))#checl that the lat/long combinations has temperature data.
#if no temperature data for the focal lat/long, choose the next closest one.
#the below code cose up to 0.1 degrees (~10km) away from the closest lat/long)
if(is.na(unique(mintest))){#if there are no temp data for the selected lat/long, chosee a different one
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
long.cell <- which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1] #select the closest longitude & latitude with climate data to longitude[i]
lat.cell <- which(diff.lat.cell==min(diff.lat.cell,na.rm=TRUE))[1]
mintest<-ncvar_get(jx,'Tmin',start=c(long.cell,lat.cell,1),count=c(1,1,-1))
if(is.na(unique(mintest))){
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
long.cell <- which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1] #select the closest longitude & latitude with climate data to longitude[i]
lat.cell <- which(diff.lat.cell==min(diff.lat.cell,na.rm=TRUE))[1]
mintest<-ncvar_get(jx,'Tmin',start=c(long.cell,lat.cell,1),count=c(1,1,-1))
if(is.na(unique(mintest))){
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
long.cell <- which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1] #select the closest longitude & latitude with climate data to longitude[i]
lat.cell <- which(diff.lat.cell==min(diff.lat.cell,na.rm=TRUE))[1]
}}}
mins <- c(mins, ncvar_get(jx,'Tmin',start=c(long.cell,lat.cell,1),count=c(1,1,-1)))#minimum temperatures for selected lat/long
maxs <- c(maxs, ncvar_get(jx,'Tmax',start=c(long.cell,lat.cell,1),count=c(1,1,-1)))#minimum temperatures for selected lat/long
nc_close(jx)
}
tempval[[as.character(nam[i,"ID_fieldsample.date2"])]] <- data.frame(Lat = la,Long = lo,Date = as.character(seq(stday, endday, by = "day")),
Tmin = mins[1:length(seq(stday, endday, by = "day"))], Tmax =maxs[1:length(seq(stday, endday, by = "day"))])
nafiles <- dir(climatedrive)[grep("livneh", dir(climatedrive))]
for(i in 1:nrow(nam)){ # i = 1
# find this location
lo <- nam[i,"chill.long"]
la <- nam[i,"chill.lat"]
# make sure longitudes are negative, need to be for North America this step is now done in "cleaning/clean_latlong" so it is no longer necessary
#if(lo > 0) { lo = lo*-1 }
yr<-as.numeric(substr(nam[i,"fieldsample.date2"],1,4))
# start and end days of the climate data we need to calculate chilling, for the focal lat/long.
#This is in days since baseline date (sept 1) Set to GMT to avoid daylight savings insanity
# using d$fieldsample.date2 (this is the same as fieldsampledate, but formatted as  "%Y-%m-%d")
#do everything in reference to field sample year becuase the year column is too variable
if(nam[i,"fieldsample.date2"]!=""){endday <- strptime(nam[i,"fieldsample.date2"],"%Y-%m-%d", tz = "GMT")}
if(nam[i,"fieldsample.date2"]==""){endday <- strptime(paste(yr, "04-30", sep="-"),"%Y-%m-%d", tz = "GMT")}#I think we have field sample dates for everything, but just in case...
if(nam[i,"fieldsample.date2"]!="" & as.numeric(substr(nam[i,"fieldsample.date2"],6,7))>=9){
stday <- strptime(paste(yr, "09-01", sep="-"),"%Y-%m-%d", tz="GMT")
chillmo<-paste(yr, formatC(9:substr(endday,6,7), width=2, flag="0"), sep="")
}#If field sample date is after september 1, then we use the chilling from the current year, since sept 1
if(nam[i,"fieldsample.date2"]!="" & as.numeric(substr(nam[i,"fieldsample.date2"],6,7))<9){
stday <- strptime(paste(yr-1, "09-01", sep="-"),"%Y-%m-%d", tz="GMT")}#
prevmo <- paste(yr-1, formatC(9:12, width=2, flag="0"), sep="");# use previous year's fall months of chilling (Sept-Dec)
endmo<-substr(endday,6,7);#month of sampling date
thismo <- paste(yr, formatC(1:endmo, width=2, flag="0"), sep="")#months from current year of chilling, through sampling date (Jan-whenever sampled)
chillmo<-c(prevmo, thismo)
}#If field sample date is before september 1, then we use the chilling from the previous year.
# Read in netCDF files to pull climate data for North America
# This requires you to work off of external hard drive
nafiles <- dir(climatedrive)[grep("livneh", dir(climatedrive))]
#loop through each lat/long for which we want to calculate chilling and pull the climate data for that lat/long
#the climate data that we are pulling is daily min and max temperature
for(i in 1:nrow(nam)){ # i = 1
# find this location
lo <- nam[i,"chill.long"]
la <- nam[i,"chill.lat"]
# make sure longitudes are negative, need to be for North America this step is now done in "cleaning/clean_latlong" so it is no longer necessary
#if(lo > 0) { lo = lo*-1 }
yr<-as.numeric(substr(nam[i,"fieldsample.date2"],1,4))
# start and end days of the climate data we need to calculate chilling, for the focal lat/long.
#This is in days since baseline date (sept 1) Set to GMT to avoid daylight savings insanity
# using d$fieldsample.date2 (this is the same as fieldsampledate, but formatted as  "%Y-%m-%d")
#do everything in reference to field sample year becuase the year column is too variable
if(nam[i,"fieldsample.date2"]!=""){endday <- strptime(nam[i,"fieldsample.date2"],"%Y-%m-%d", tz = "GMT")}
if(nam[i,"fieldsample.date2"]==""){endday <- strptime(paste(yr, "04-30", sep="-"),"%Y-%m-%d", tz = "GMT")}#I think we have field sample dates for everything, but just in case...
if(nam[i,"fieldsample.date2"]!="" & as.numeric(substr(nam[i,"fieldsample.date2"],6,7))>=9){
stday <- strptime(paste(yr, "09-01", sep="-"),"%Y-%m-%d", tz="GMT")
chillmo<-paste(yr, formatC(9:substr(endday,6,7), width=2, flag="0"), sep="")
}#If field sample date is after september 1, then we use the chilling from the current year, since sept 1
if(nam[i,"fieldsample.date2"]!="" & as.numeric(substr(nam[i,"fieldsample.date2"],6,7))<9){
stday <- strptime(paste(yr-1, "09-01", sep="-"),"%Y-%m-%d", tz="GMT")#
prevmo <- paste(yr-1, formatC(9:12, width=2, flag="0"), sep="");# use previous year's fall months of chilling (Sept-Dec)
endmo<-substr(endday,6,7);#month of sampling date
thismo <- paste(yr, formatC(1:endmo, width=2, flag="0"), sep="")#months from current year of chilling, through sampling date (Jan-whenever sampled)
chillmo<-c(prevmo, thismo)
}#If field sample date is before september 1, then we use the chilling from the previous year.
# now loop over these year-month combo files and get temperature values for this date range.
mins <- maxs <- vector()
for(j in c(chillmo)){ # j = "200009"
file <- file.path(climatedrive,nafiles[grep(j, nafiles)])
jx <- nc_open(file)
diff.long.cell <- abs(jx$dim$lon$vals-as.numeric(lo))#differences between all longitudes & latitudes in the focal month's dataset and longitude[i]
diff.lat.cell <- abs(jx$dim$lat$vals-as.numeric(la))
long.cell <- which(diff.long.cell==min(diff.long.cell))[1] #select the closest longitude & latitude with climate data to longitude[i]
lat.cell <- which(diff.lat.cell==min(diff.lat.cell))[1]
long.cell <- which.min(abs(jx$dim$lon$vals-as.numeric(lo)))
lat.cell <- which.min(abs(jx$dim$lat$vals-as.numeric(la)))
mintest<-ncvar_get(jx,'Tmin',start=c(long.cell,lat.cell,1),count=c(1,1,-1))#checl that the lat/long combinations has temperature data.
#if no temperature data for the focal lat/long, choose the next closest one.
#the below code cose up to 0.1 degrees (~10km) away from the closest lat/long)
if(is.na(unique(mintest))){#if there are no temp data for the selected lat/long, chosee a different one
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
long.cell <- which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1] #select the closest longitude & latitude with climate data to longitude[i]
lat.cell <- which(diff.lat.cell==min(diff.lat.cell,na.rm=TRUE))[1]
mintest<-ncvar_get(jx,'Tmin',start=c(long.cell,lat.cell,1),count=c(1,1,-1))
if(is.na(unique(mintest))){
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
long.cell <- which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1] #select the closest longitude & latitude with climate data to longitude[i]
lat.cell <- which(diff.lat.cell==min(diff.lat.cell,na.rm=TRUE))[1]
mintest<-ncvar_get(jx,'Tmin',start=c(long.cell,lat.cell,1),count=c(1,1,-1))
if(is.na(unique(mintest))){
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
diff.long.cell[which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1]]<-NA
long.cell <- which(diff.long.cell==min(diff.long.cell,na.rm=TRUE))[1] #select the closest longitude & latitude with climate data to longitude[i]
lat.cell <- which(diff.lat.cell==min(diff.lat.cell,na.rm=TRUE))[1]
}}}
mins <- c(mins, ncvar_get(jx,'Tmin',start=c(long.cell,lat.cell,1),count=c(1,1,-1)))#minimum temperatures for selected lat/long
maxs <- c(maxs, ncvar_get(jx,'Tmax',start=c(long.cell,lat.cell,1),count=c(1,1,-1)))#minimum temperatures for selected lat/long
nc_close(jx)
}
tempval[[as.character(nam[i,"ID_fieldsample.date2"])]] <- data.frame(Lat = la,Long = lo,Date = as.character(seq(stday, endday, by = "day")),
Tmin = mins[1:length(seq(stday, endday, by = "day"))], Tmax =maxs[1:length(seq(stday, endday, by = "day"))])
}
tempval[[as.character(nam[i,"ID_fieldsample.date2"])]]
tempval$`schnabel87_46.206_-119.767_1984-11-29_0`
tempval$`schnabel87_46.206_-119.767_1984-10-11_0`
tempval$`spann04_29.652_-82.325_2001-01-03_0`
## Estimate total chilling and add to the OSPREE data ##
## By Ailene Ettinger, Dan Flynn, Lizzie and more! ###
## See _chillingREADME.txt in same folder for more info ##
## housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory:
if(length(grep("Lizzie", getwd())>0)) {setwd("~/Documents/git/projects/treegarden/budreview/ospree/analyses")
} else if
(length(grep("ailene", getwd()))>0) {setwd("/Users/aileneettinger/git/ospree/analyses")
}else
setwd("~/Documents/git/ospree/analyses")
<<<<<<< Updated upstream
# make sure this is the correct file (we're still cleaning as I write this!)
bb <- read.csv("output/ospree_clean_withchill_BB.csv", header=TRUE)
taxon <- read.csv("output/bb_analysis/taxon/complex_levels.csv", header=TRUE)
respvars.thatwewant <- c("daystobudburst", "percentbudburst")
bb.resp <- bb[which(bb$respvar.simple %in% respvars.thatwewant),]
bb.resp <- subset(bb.resp, respvar != "thermaltime") # doesn't remove anything
## make a bunch of things numeric (eek!)
bb.resp$forceday <- as.numeric(bb.resp$forcetemp)
bb.resp$forcenight <- as.numeric(bb.resp$forcetemp_night)
bb.resp$photonight <- as.numeric(bb.resp$photoperiod_night)
bb.resp$photo <- as.numeric(bb.resp$photoperiod_day)
bb.resp$force <- bb.resp$forceday
bb.resp$force[is.na(bb.resp$forcenight)==FALSE & is.na(bb.resp$photo)==FALSE &
is.na(bb.resp$photonight)==FALSE] <-
(bb.resp$forceday[is.na(bb.resp$forcenight)==FALSE & is.na(bb.resp$photo)==FALSE &
is.na(bb.resp$photonight)==FALSE]*
bb.resp$photo[is.na(bb.resp$forcenight)==FALSE & is.na(bb.resp$photo)==FALSE &
is.na(bb.resp$photonight)==FALSE] +
bb.resp$forcenight[is.na(bb.resp$forcenight)==FALSE & is.na(bb.resp$photo)==FALSE &
is.na(bb.resp$photonight)==FALSE]*
bb.resp$photonight[is.na(bb.resp$forcenight)==FALSE & is.na(bb.resp$photo)==FALSE &
is.na(bb.resp$photonight)==FALSE])/24
bb.resp$chill <- as.numeric(bb.resp$Total_Utah_Model) # before 12 March 2018: Total_Chilling_Hours, Total_Chill_portions
bb.resp$resp <- as.numeric(bb.resp$response.time)
# merge in labgroup (we could do this elsewhere someday)
bb.wlab <- merge(bb.resp, taxon, by=c("genus","species"), all.x=TRUE)
tt <- table(bb.wlab$complex)
bb.wlab <- subset(bb.wlab, complex %in% names(tt[tt > 100])) ### testing
# [1] "Betula_complex"        "Betula_pendula"        "Betula_pubescens"      "Fagus_sylvatica"
# [5] "Malus_domestica"       "Picea_abies"           "Picea_glauca"          "Pseudotsuga_menziesii"
# [9] "Ribes_nigrum"          "Ulmus_complex"
myspp<-c("Betula_complex", "Betula_pendula", "Betula_pubescens", "Fagus_sylvatica", "Picea_abies", "Picea_glauca","Pseudotsuga_menziesii", "Ulmus_complex")
bb.wlab<-dplyr::filter(bb.wlab, complex%in%myspp)
columnstokeep <- c("datasetID", "genus", "species", "varetc", "woody", "forcetemp",
"photoperiod_day", "response", "response.time", "Total_Chill_portions",
"complex", "provenance.lat")
bb.wlab.sm <- subset(bb.wlab, select=columnstokeep)
## make a bunch of things numeric (eek!)
bb.wlab.sm$force <- as.numeric(bb.wlab.sm$forcetemp)
bb.wlab.sm$photo <- as.numeric(bb.wlab.sm$photoperiod_day)
bb.wlab.sm$chill <- as.numeric(bb.wlab.sm$Total_Chill_portions)
bb.wlab.sm$resp <- as.numeric(bb.wlab.sm$response.time)
bb.wlab.sm$lat<-as.numeric(bb.wlab.sm$provenance.lat)
## subsetting data, preparing genus variable, removing NAs
ospr.prepdata <- subset(bb.wlab.sm, select=c("resp", "chill", "photo", "force", "complex", "lat"))
dim(subset(bb.wlab.sm, is.na(chill)==FALSE & is.na(photo)==FALSE & is.na(force)==FALSE
& is.na(lat)==FALSE))
ospr.stan <- ospr.prepdata[complete.cases(ospr.prepdata),]
ospr.stan$sp <- as.numeric(as.factor(ospr.stan$complex))
## Center?
#ospr.stan$cchill<-ospr.stan$chill/24
#ospr.stan$cforce<- scale(ospr.stan$force, center=TRUE)
#ospr.stan$cchill<- scale(ospr.stan$cchill, center=TRUE)
#ospr.stan$cphoto<- scale(ospr.stan$photo, center=TRUE)
#ospr.stan$clat<- scale(ospr.stan$lat, center=TRUE)
ospr.stan$presp<-ospr.stan$resp+1
ospr.stan$presp<-as.integer(round(ospr.stan$presp, digits=0))
ospr.stan<-ospr.stan[which(ospr.stan$presp!=1000),]
lat.brm.uncent<-brm(presp~ force + photo + chill + lat + force:photo + force:chill + photo:chill + force:lat + photo:lat +
chill:lat + (1|sp) + (force-1|sp) + (photo-1|sp)
+ (chill-1|sp) + (lat-1|sp) + (photo:lat-1|sp) +
(force:photo-1|sp) + (force:chill-1|sp) + (force:lat-1|sp) +
(photo:chill-1|sp) + (chill:lat-1|sp), data=ospr.stan, family=poisson, chains=2)
## Center?
#ospr.stan$cchill<-ospr.stan$chill/24
#ospr.stan$cforce<- scale(ospr.stan$force, center=TRUE)
#ospr.stan$cchill<- scale(ospr.stan$cchill, center=TRUE)
#ospr.stan$cphoto<- scale(ospr.stan$photo, center=TRUE)
#ospr.stan$clat<- scale(ospr.stan$lat, center=TRUE)
ospr.stan$chill<-ospr.stan$chill+1
lat.brm.uncent<-brm(presp~ force + photo + chill + lat + force:photo + force:chill + photo:chill + force:lat + photo:lat +
chill:lat + (1|sp) + (force-1|sp) + (photo-1|sp)
+ (chill-1|sp) + (lat-1|sp) + (photo:lat-1|sp) +
(force:photo-1|sp) + (force:chill-1|sp) + (force:lat-1|sp) +
(photo:chill-1|sp) + (chill:lat-1|sp), data=ospr.stan, family=poisson, chains=2)
lat.stan<-stan_glmer(presp~ force + photo + chill + lat + force:photo + force:chill + photo:chill + force:lat + photo:lat +
chill:lat + (1|sp), data=ospr.stan, family=poisson, chains=2)
pp_checks(lat.stan)
pp_check(lat.stan)
lat.stan
lat.brm.uncent<-brm(presp~ force + photo + chill + lat + force:photo + force:chill + photo:chill + force:lat + photo:lat +
chill:lat + (1|sp), data=ospr.stan, family=poisson, chains=2)
lat.brm.uncent<-brm(presp~ force + photo + chill + lat + force:photo + force:chill + photo:chill + force:lat + photo:lat +
chill:lat + (1|sp) + (force-1|sp) + (photo-1|sp)
+ (chill-1|sp) + (lat-1|sp) + (photo:lat-1|sp) +
(force:photo-1|sp) + (force:chill-1|sp) + (force:lat-1|sp) +
(photo:chill-1|sp) + (chill:lat-1|sp), data=ospr.stan, family=poisson(), chains=2)
ospr.stan <- ospr.prepdata[complete.cases(ospr.prepdata),]
ospr.stan$sp <- as.numeric(as.factor(ospr.stan$complex))
## Center?
#ospr.stan$cchill<-ospr.stan$chill/24
ospr.stan$cforce<- scale(ospr.stan$force, center=TRUE)
ospr.stan$cchill<- scale(ospr.stan$chill, center=TRUE)
ospr.stan$cphoto<- scale(ospr.stan$photo, center=TRUE)
ospr.stan$clat<- scale(ospr.stan$lat, center=TRUE)
#ospr.stan$chill<-ospr.stan$chill+1
ospr.stan$presp<-ospr.stan$resp+1
ospr.stan$presp<-as.integer(round(ospr.stan$presp, digits=0))
lat.brm<-brm(presp~ cforce + cphoto + cchill + clat + cforce:cphoto + cforce:cchill + cphoto:cchill + cforce:clat + cphoto:clat +
cchill:clat + (1|sp) + (cforce-1|sp) + (cphoto-1|sp)
+ (cchill-1|sp) + (clat-1|sp) + (cphoto:clat-1|sp) +
(cforce:cphoto-1|sp) + (cforce:cchill-1|sp) + (cforce:clat-1|sp) +
(cphoto:cchill-1|sp) + (cchill:clat-1|sp), data=ospr.stan, family=poisson, chains=2)
=======
# Load libraries
library(dplyr)
library(tidyr)
library(plyr)
library(ncdf4)
library(Interpol.T)
library(chillR)
# 1. Get the data
d <- read.csv("output/ospree_clean.csv")
# 2. Clean the chilltemp column
source("chilling/cleaning_chilltemp.R")
#3. Clean the provenance.latitude and provenance.longitude columns, to get appropriate locations
#source("chilling/cleaning_provlatlong.R")
#This step was moved to the cleaning folder
# 4. Estimate field chilling (using growing or provenance lat/long to pull climate data)- STEP 4B REQUIRES EXTERNAL HARD DRIVE
# 4a: summarize lat/longs needed to pull climate data from europe and north america
source("chilling/fieldchillcalc_latlong.R")
climatedrive = "/Volumes/climate" #Ailene's climate data drive
# 4c. pull climate data from europe
source("chilling/pullclimate_eur.R")
# 4d: pull climate data from north america
#tempval <- list() #required to just pull nam climate
source("chilling/pullclimate_nam2.R")
# 4e: Interpolate hourly temperatures from the daily values
# & chilling using three different metrics
#(If you want to avoid connecting to the external hard drive, then start here)
#load this .RData workspace)
#load("output/fieldclimate.RData")
source("chilling/interpolclimate.R")
source("chilling/totalchillcalc.R")
write.csv(dat4, "output/ospree_clean_withchill.csv", row.names=FALSE) ##
dat4$missingCH<-0
dat4$missingCH[which(is.na(dat4$Total_Chilling_Hours))]<-1
chilltab<-table(dat4$datasetID,dat4$missingCH)
missing<-chilltab[chilltab[,2]>0,]
missing
chilltab
>>>>>>> Stashed changes
